{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01705e21",
   "metadata": {},
   "source": [
    "Vector Search Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e3ece1",
   "metadata": {},
   "source": [
    "## 1. Importación de librerías y conexión con Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc86d417",
   "metadata": {},
   "source": [
    "Primero asegúrate de correr e instalar las dependencias necesarias\n",
    "Y dejar el contenedor corriendo. <p>\n",
    "Setup: [set_up_qdrant]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de8b4e1",
   "metadata": {},
   "source": [
    "Importación de librerías\n",
    "- Clase `QdrantClient`: permite establecer conexión con el servicio de Qdrant.\n",
    "- Módulo `models`: permite establecer configuraciones y parámetros necesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2c867a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d56c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el cliente\n",
    "client = QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2ef34d",
   "metadata": {},
   "source": [
    "## 2. Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5a0b20",
   "metadata": {},
   "source": [
    "Hay que entender el dataset, conocer principalmente:\n",
    "- Qué tipo de contenido es? imagen, video, texto o combinación\n",
    "- Especificar: Si es texto, entonces qué lenguaje es, contiene caracteres especiales?\n",
    "\n",
    "¿Porqué es necesario responder estas preguntas?\n",
    "Para definir:\n",
    "- El tipo de esquema para los datos. (¿qué es lo se va a vectorizar?, ¿Qué se va a almacenar en la metadata?)\n",
    "- El modelo correcto del embedding. Tenemos que evaluar diferentes parámetros como el dominio, la precisión y los recursos requeridos           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be548526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación del dataset\n",
    "# pip install requests\n",
    "import requests\n",
    "\n",
    "ruta_doc= 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_rpta= requests.get(ruta_doc)\n",
    "documentos = docs_rpta.json()\n",
    "# documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13cd39bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de documentos:3\n",
      "Data type de documentos:<class 'list'>\n",
      "Data type de dato del primer elemento de documentos:<class 'dict'>\n",
      "\n",
      "Cursos del FaQ Zoomcamp:\n",
      "- data-engineering-zoomcamp\n",
      "- machine-learning-zoomcamp\n",
      "- mlops-zoomcamp\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tamaño de documentos:{len(documentos)}\")\n",
    "print(f\"Data type de documentos:{type(documentos)}\")\n",
    "print(f\"Data type de dato del primer elemento de documentos:{type(documentos[0])}\")\n",
    "\n",
    "print('\\nCursos del FaQ Zoomcamp:')\n",
    "for i in documentos:\n",
    "    print(f\"- {i['course']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b23fcc6",
   "metadata": {},
   "source": [
    "Entonces, después de analizar `documentos`, la información relevante es:\n",
    "- Tamaño: 3 elementos\n",
    "- Lista de diccionarios\n",
    "\n",
    "Estructura de `documentos` <p>\n",
    "\n",
    "```git bash\n",
    "[\n",
    "    {'course':'data-engineering-zoomcamp',\n",
    "    'documents': [{'text': ' ' , 'section':' '  , 'question':' '  },\n",
    "                  {'text': ' ' , 'section':' '  , 'question':' '  },\n",
    "                                 ...                    \n",
    "                {'text':  , 'section':  , 'question':  } ]\n",
    "    \n",
    "    }, \n",
    "    {'course':'machine-learning-zoomcamp',\n",
    "    'documents': [{'text':  , 'section':  , 'question':  },\n",
    "                  {'text':  , 'section':  , 'question':  },\n",
    "                                 ...                    \n",
    "                {'text':  , 'section':  , 'question':  } ]\n",
    "    \n",
    "    }, \n",
    "    {'course':'mlops-zoomcamp',\n",
    "    'documents': [{'text':  , 'section':  , 'question':  },\n",
    "                  {'text':  , 'section':  , 'question':  },\n",
    "                                 ...                    \n",
    "                {'text':  , 'section':  , 'question':  } ]\n",
    "    } \n",
    "]\n",
    "```\n",
    "\n",
    "Cada elemento de la lista es un diccionario, que contiene 2 elementos(course y documents). <p>\n",
    "Del cual documents es también una lista de diccionarios, donde cada diccionario contiene 3 elementos(text, section, question)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb6bad",
   "metadata": {},
   "source": [
    "1. Verificamos que la data se encuentra limpia y fragmentada (chunk, divide la data en pequeñas partes porque es más fácil para los modelos de embeddings procesarla)\n",
    "2. Tenemos que definir\n",
    "    - Los campos(fields) para semantic_search\n",
    "    - Campos para almacenar como *metadata*, pueden ser usados como filtros "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fc265f",
   "metadata": {},
   "source": [
    "3. Se definen: \n",
    "    - Campos para semantic search: question, text\n",
    "    - Campos para metadata(también como filtros): course, section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de69774",
   "metadata": {},
   "source": [
    "## 3. Elección del modelo de embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e8c08",
   "metadata": {},
   "source": [
    "Los modelos de embeddings como ya lo hemos mencionado permite convertir la data en vectores. Para escoger un 'buen' modelo, depende ciertos factores:\n",
    "- La tarea, el tipo de dato y sus características. (texto, inglés )\n",
    "- La evaluación entre la 'precisión de búsqueda' y los 'recursos usados' (embeddings más grandes requieren más almacenamiento y memoria)\n",
    "- El costo de deducir(o inferir) \n",
    "etc\n",
    "\n",
    "La mejor manera de escoger el modelo es testear diferentes opciones en tu propia data. <p>\n",
    "En este caso, vamos a utilizar FastEmbed. <p>\n",
    "Documentación: [FastEmbed](https://github.com/qdrant/fastembed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f0178f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'BAAI/bge-base-en',\n",
       "  'sources': {'hf': 'Qdrant/fast-bge-base-en',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-base-en.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.42,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-base-en-v1.5',\n",
       "  'sources': {'hf': 'qdrant/bge-base-en-v1.5-onnx-q',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-base-en-v1.5.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.21,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-large-en-v1.5',\n",
       "  'sources': {'hf': 'qdrant/bge-large-en-v1.5-onnx',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 1.2,\n",
       "  'additional_files': [],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-small-en',\n",
       "  'sources': {'hf': 'Qdrant/bge-small-en',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/BAAI-bge-small-en.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.13,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-small-en-v1.5',\n",
       "  'sources': {'hf': 'qdrant/bge-small-en-v1.5-onnx-q',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.067,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "\n",
    "# modelos disponibles\n",
    "modelos= TextEmbedding.list_supported_models()\n",
    "\n",
    "# primeros 5 modelos\n",
    "modelos[:5] \n",
    "\n",
    "# modelo_embedding= TextEmbedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9098e017",
   "metadata": {},
   "source": [
    "Es lógico que nuestro modelo no produzca una alta dimensionalidad para evitar usar recursos de más, por lo tanto nos declinamos por una moderada dimensionalidad (Ej: 512 dimensionalidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66d4bf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model\": \"BAAI/bge-small-zh-v1.5\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"Qdrant/bge-small-zh-v1.5\",\n",
      "    \"url\": \"https://storage.googleapis.com/qdrant-fastembed/fast-bge-small-zh-v1.5.tar.gz\",\n",
      "    \"_deprecated_tar_struct\": true\n",
      "  },\n",
      "  \"model_file\": \"model_optimized.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), Chinese, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 0.09,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"Qdrant/clip-ViT-B-32-text\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"Qdrant/clip-ViT-B-32-text\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"model.onnx\",\n",
      "  \"description\": \"Text embeddings, Multimodal (text&image), English, 77 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 0.25,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"jinaai/jina-embeddings-v2-small-en\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"xenova/jina-embeddings-v2-small-en\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"onnx/model.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.\",\n",
      "  \"license\": \"apache-2.0\",\n",
      "  \"size_in_GB\": 0.12,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# para formatear la salida con indentacion\n",
    "import json\n",
    "\n",
    "dimension= 512\n",
    "for i in modelos:\n",
    "    if i['dim'] == dimension:\n",
    "        print (json.dumps(i, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33459847",
   "metadata": {},
   "source": [
    "El modelo 1: `BAAI/bge-small-zh-v1.5`\n",
    "- Para texto pero para lenguaje Chino, descartado\n",
    "\n",
    "El modelo 2: `Qdrant/clip-ViT-B-32-text`\n",
    "- Multimoda, Para texto e imágenes, pero no es necesario impágenes, descartado\n",
    "\n",
    "El modelo 3: `jinaai/jina-embeddings-v2-small-en`\n",
    "- El más adecuado descartando los previos\n",
    "- [Documentación del modelo usado para embedding](https://huggingface.co/jinaai/jina-embeddings-v2-small-en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfa0e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_seleccionado= \"jinaai/jina-embeddings-v2-small-en\"\n",
    "\n",
    "# Este modelo como muchos, fue entrenado usando similitud de coseno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91408d3",
   "metadata": {},
   "source": [
    "Ahora ya estamos listos para configurar los parámetros del modelo con **Qdrant** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb77b84",
   "metadata": {},
   "source": [
    "## 4. Configuración con Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c69fda",
   "metadata": {},
   "source": [
    "### Creación de una colección:\n",
    "Debemos definir:\n",
    "- Nombre\n",
    "- Configuración del vector: \n",
    "    -  Size, dimensionalidad del vector\n",
    "    - Distance Metric: el método para medir la similitud entre vectores\n",
    "    Tipo de métodos: dot, cosine Euclid, manhatthan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49785bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from qdrant_client import QdrantClient, models\n",
    "# client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "nombre_coleccion= 'zoomcamp-rag'\n",
    "client.create_collection(\n",
    "    collection_name= nombre_coleccion, \n",
    "    vectors_config=models.VectorParams(\n",
    "        size= dimension, \n",
    "        distance= models.Distance.COSINE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905ca9ad",
   "metadata": {},
   "source": [
    "### Crear e insertar Points en la Colección\n",
    "Recordar que la definción de un Point es `P(ID, vector, payload(opcional))`\n",
    "Explicación más detallada en [set_up_qdrant](02_Week_vector_search/set_up_qdrant.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c32e861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jinaai/jina-embeddings-v2-small-en'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_seleccionado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7b77ea",
   "metadata": {},
   "source": [
    "Creación de puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b570feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para almacenar los puntos\n",
    "points= []\n",
    "id=0 #por defecto el identificador de los puntos 0 \n",
    "\n",
    "for i in documentos:\n",
    "    for j in i['documents']: # text-section -question\n",
    "        # print(j)\n",
    "        point = models.PointStruct(\n",
    "            id= id, \n",
    "            vector= models.Document(text= j['text'], model= modelo_seleccionado), \n",
    "            payload= {\n",
    "                \"text\": j['text'], \n",
    "                \"section\":j['section'], \n",
    "                \"course\": i['course']\n",
    "            }\n",
    "        )\n",
    "        points.append(point)\n",
    "        id +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d2a0e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PointStruct(id=0, vector=Document(text=\"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\", model='jinaai/jina-embeddings-v2-small-en', options=None), payload={'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\", 'section': 'General course-related questions', 'course': 'data-engineering-zoomcamp'}),\n",
       " PointStruct(id=1, vector=Document(text='GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites', model='jinaai/jina-embeddings-v2-small-en', options=None), payload={'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites', 'section': 'General course-related questions', 'course': 'data-engineering-zoomcamp'}),\n",
       " PointStruct(id=2, vector=Document(text=\"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\", model='jinaai/jina-embeddings-v2-small-en', options=None), payload={'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\", 'section': 'General course-related questions', 'course': 'data-engineering-zoomcamp'}),\n",
       " PointStruct(id=3, vector=Document(text=\"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\", model='jinaai/jina-embeddings-v2-small-en', options=None), payload={'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\", 'section': 'General course-related questions', 'course': 'data-engineering-zoomcamp'})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c4ebf",
   "metadata": {},
   "source": [
    "Finalmente se resume este notebook para un sistema Rag con Vector Search. \n",
    "[colocar el notebook de rag]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
