# üìò Apuntes ‚Äì Semana 1

## 1. ¬øQu√© es un LLM?

Los LLM (Large Language Models) son modelos entrenados con grandes cantidades de texto para generar y comprender lenguaje natural. Voy usar el llm GPT de OpenAI.

## 2. ¬øQu√© es RAG (Retrieval-Augmented Generation)?

Un sistema RAG se basa en buscar informaci√≥n relevante para d√°rsela al modelo antes de que genere la respuesta. Esto permite respuestas m√°s precisas y actualizadas.

### üîÅ Flujo de un sistema RAG:
1. El usuario hace una pregunta
2. El sistema busca en una base de datos/documentos
3. Se selecciona el texto m√°s relevante
4. Se construye un prompt: contexto + pregunta
5. Se env√≠a al LLM y se genera la respuesta

## 3. Implementaci√≥n del motor de b√∫squeda (`minsearch.py`)

Esta archivo implementa un motor de b√∫squeda usado en las primeras clases. 
Se utiliza la b√∫squeda tradicional o Minsearch, se basa en:
- TF-IDF: 
T√©cnica de *NLP* donde se eval√∫a el `peso` de cada palabra que pertenece a un documento.

- Similitud de coseno: Eval√∫a similitud de vectores a trav√©s del √°ngulo entre ellos.

Archivo [minsearch.py]() 

## 4. Prompt Engineering b√°sico

Un LLM necesita contexto, en este caso se desarrolla un prompt con la instrucci√≥n, pregunta o query y contexto(o informaci√≥n).

```
INTRUCCI√ìN: Eres un asistente ...

QUERY: {query}
CONTEXT: {context}
```

## 5. Modularizaci√≥n

Se modulariz√≥ por las siguientes funciones:
- Busqueda por index `busqueda`
- Ordena documentos (section, question, text) y generaci√≥n del prompt `build_prompt`
- Generaci√≥n del ouput `chat_llm`

Finalmente, todo se construy√≥ en una funci√≥n final `rag`:
- Par√°metros de entrada: query, course
- Retorna: La respuesta del llm



---
**Recursos Adicionales:**
- [ Apuntes TF-IDF]() 
- [M√©todo TF-IDF - Youtube](https://www.youtube.com/watch?v=CBKT-dVnrQo&ab_channel=C%C3%B3digoEspinoza-AutomatizatuVida)
- [Repo Minsearch](https://github.com/alexeygrigorev/minsearch/tree/main) de Alexey Grigorev-Fundador de DataTalskClub