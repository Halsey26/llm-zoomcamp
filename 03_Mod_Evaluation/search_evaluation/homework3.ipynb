{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84c22576",
   "metadata": {},
   "source": [
    "# HomeWork 3\n",
    "En este módulo se ha realizado la evaluación de búsqueda por similitud semántica. <p>\n",
    "Sin embargo, en este Homework se evaluará por **búsqueda vectorial**\n",
    "- Script: [Homework Evaluation](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/cohorts/2025/03-evaluation/homework.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7042c7",
   "metadata": {},
   "source": [
    "Obtenemos:\n",
    "- documentos con id\n",
    "- ground_truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c298a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url_prefix = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-evaluation/'\n",
    "docs_url = url_prefix + 'search_evaluation/documents-with-ids.json'\n",
    "documents = requests.get(docs_url).json()\n",
    "\n",
    "ground_truth_url = url_prefix + 'search_evaluation/ground-truth-data.csv'\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafb76d7",
   "metadata": {},
   "source": [
    "Métricas de evaluación y función para evaluar cada documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba7a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f61eabce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluacion_metricas(ground_truth,funcion_busqueda ): \n",
    "    relevantes= []\n",
    "    print('Otención de resultados relevantes: [True, False, False, False, False], ...')\n",
    "    for doc_groundt in tqdm(ground_truth):\n",
    "        id_groundt= doc_groundt['document']\n",
    "        resultados_search= funcion_busqueda(doc_groundt['question'], doc_groundt['course'] )\n",
    "        \n",
    "        relevante_registo = []\n",
    "\n",
    "        for result in resultados_search:\n",
    "            relevante_registo.append(id_groundt == result['id']  )\n",
    "        # lo mismo: relevantes_registro = [result['id] == id_groundt for result in resultados_search]\n",
    "        \n",
    "        relevantes.append(relevante_registo)\n",
    "    \n",
    "    evaluacion_hr= hit_rate(relevantes)\n",
    "    evaluacion_mrr= mrr(relevantes)\n",
    "\n",
    "\n",
    "    return {'Evaluacion HR ': evaluacion_hr,  'Evaluacion MRR': evaluacion_mrr}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be39acb1",
   "metadata": {},
   "source": [
    "## Q1\n",
    "Now let's evaluate our usual minsearch approach. What's the hitrate for this approach?\n",
    "Indexamos según indican en el enunciado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeb72915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x7bba8c1cf9e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indezxamos\n",
    "import minsearch\n",
    "\n",
    "#indexacion\n",
    "index= minsearch.Index(\n",
    "    text_fields=[\"question\", \"section\", \"text\"], \n",
    "    keyword_fields=['course', 'id']\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56fd509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función búsqueda\n",
    "def search_minsearch(query, course):\n",
    "    resultados= index.search(\n",
    "        query= query, \n",
    "        boost_dict = {'question': 1.5, 'section': 0.1},\n",
    "        filter_dict= {\"course\": course} ,\n",
    "        num_results= 5\n",
    "    )\n",
    "\n",
    "    return resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4a5d1ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'You can set it up on your laptop or PC if you prefer to work locally from your laptop or PC.\\nYou might face some challenges, especially for Windows users. If you face cnd2\\nIf you prefer to work on the local machine, you may start with the week 1 Introduction to Docker and follow through.\\nHowever, if you prefer to set up a virtual machine, you may start with these first:\\nUsing GitHub Codespaces\\nSetting up the environment on a cloudV Mcodespace\\nI decided to work on a virtual machine because I have different laptops & PCs for my home & office, so I can work on this boot camp virtually anywhere.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Environment - Should I use my local machine, GCP, or GitHub Codespaces for my environment?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'ddf6c1b3'},\n",
       " {'text': 'Choose the approach that aligns the most with your idea for the end project\\nOne of those should suffice. However, BigQuery, which is part of GCP, will be used, so learning that is probably a better option. Or you can set up a local environment for most of this course.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Environment - Do I need both GitHub Codespaces and GCP?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '3c0114ce'},\n",
       " {'text': \"It's up to you which platform and environment you use for the course.\\nGithub codespaces or GCP VM are just possible options, but you can do the entire course from your laptop.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Environment - Do we really have to use GitHub codespaces? I already have PostgreSQL & Docker installed.',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '251218fc'},\n",
       " {'text': 'Instruction on how to store secrets that will be avialable in GitHub  Codespaces.\\nManaging your account-specific secrets for GitHub Codespaces - GitHub Docs',\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': 'GitHub Codespaces - How to store secrets',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '543ff080'},\n",
       " {'text': 'GitHub Codespaces offers you computing Linux resources with many pre-installed tools (Docker, Docker Compose, Python).\\nYou can also open any GitHub repository in a GitHub Codespace.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Environment - Is GitHub codespaces an alternative to using cli/git bash to ingest the data and create a docker file?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'ac25d3af'}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_minsearch(question_20, \"data-engineering-zoomcamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3890a570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinSearch\n",
      "Otención de resultados relevantes: [True, False, False, False, False], ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4627/4627 [00:15<00:00, 295.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Evaluacion HR ': 0.848714069591528, 'Evaluacion MRR': 0.7288235717887772}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('MinSearch')\n",
    "evaluacion_metricas(ground_truth, search_minsearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a04487b",
   "metadata": {},
   "source": [
    "- **Hitrate**: 0.8487"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5278c35",
   "metadata": {},
   "source": [
    "## Q2. Vector search for question\n",
    "Evaluate this seach method. What's MRR for it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3562662b",
   "metadata": {},
   "source": [
    "Embedding para las preguntas(questions) de documentos.\n",
    "- Se generarán usando TF- IDF y  Singular Value Decomposition.\n",
    "- Más detalles: [Build Your Own Search Engine](https://github.com/alexeygrigorev/build-your-own-search-engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb789e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question']\n",
    "    texts.append(t)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "\n",
    "# fit espera una lista de documentos\n",
    "X = pipeline.fit_transform(texts) # se realiza el embedding de cada question\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b483acd",
   "metadata": {},
   "source": [
    "Usando VectorSearch de minsearch, se indexan las preguntas ya vectorizadas con los documentos.\n",
    "Verificar última versión:\n",
    "- `pip install -U minsearch qdrant_client`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0c350a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x7bba86aa37a0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minsearch.vector import VectorSearch\n",
    "\n",
    "vindex = VectorSearch(keyword_fields=['course'])\n",
    "vindex.fit(X, documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42251d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b7844",
   "metadata": {},
   "source": [
    "Creamos la función de búsqueda vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8eaaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(query, course):\n",
    "    \n",
    "    \n",
    "    return vindex.search(\n",
    "        query, #questions embebidas, en este X\n",
    "        filter_dict={'course': course}, \n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "def resultados_Vsearch(query, course): \n",
    "    # question= document['question']\n",
    "    # course= document['course']\n",
    "    # como ya se realizó fit_transform, ya se entrenó, entonces solo sería necesario transform, y como se espera una lista []\n",
    "    question_embed= pipeline.transform([query])\n",
    "\n",
    "    return vector_search(question_embed, course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9866b1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Search\n",
      "Otención de resultados relevantes: [True, False, False, False, False], ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4627/4627 [00:07<00:00, 612.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Evaluacion HR ': 0.48173762697212014, 'Evaluacion MRR': 0.3572833369353793}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Vector Search')\n",
    "evaluacion_metricas(ground_truth, resultados_Vsearch )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1fd4ae",
   "metadata": {},
   "source": [
    "- **MRR**: 0.357"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46191323",
   "metadata": {},
   "source": [
    "## Q3. Vector Search for question and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bbaa137c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x7bba73c35c70>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos los embedding para question+answer\n",
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question']  + ' ' + doc['text']\n",
    "    texts.append(t)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "\n",
    "# fit espera una lista de documentos\n",
    "X = pipeline.fit_transform(texts) # se realiza el embedding de cada question\n",
    "\n",
    "# Indexación\n",
    "vindex = VectorSearch(keyword_fields=['course'])\n",
    "vindex.fit(X, documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e929bef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Search (question+answer)\n",
      "Otención de resultados relevantes: [True, False, False, False, False], ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4627/4627 [00:07<00:00, 598.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Evaluacion HR ': 0.8210503566025502, 'Evaluacion MRR': 0.6717347453353508}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Vector Search (question+answer)')\n",
    "evaluacion_metricas(ground_truth, resultados_Vsearch )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4332a",
   "metadata": {},
   "source": [
    "- **HR**: 0.82\n",
    "\n",
    "NOTA: Vemos un claro incremento de aproximadamente el doble en ambas métricas, cuando se añade las respuestas y no solo se usa las preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8d3e47",
   "metadata": {},
   "source": [
    "## Q4. Qdrant\n",
    "Evaluación con las siguientes configuraciones:\n",
    "- text = doc['question'] + ' ' + doc['text']\n",
    "- model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "- limit = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f546fbc",
   "metadata": {},
   "source": [
    "Más detalles en: \n",
    "- Setup: [set_up_qdrant](https://github.com/Halsey26/llm-zoomcamp/blob/main/02_Mod_vector_search/set_up_qdrant.md)\n",
    "- [Vector_search_qdrant](https://github.com/Halsey26/llm-zoomcamp/blob/main/02_Mod_vector_search/vector_search_qdrant.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9411edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "# Inicializamos el cliente\n",
    "cliente = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "modelo = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "dimension= 512\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc461d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:07<00:00,  1.57s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coleccion\n",
    "\n",
    "nombre_coleccion= 'homework3'\n",
    "cliente.create_collection(\n",
    "    collection_name= nombre_coleccion, \n",
    "    vectors_config=models.VectorParams(\n",
    "        size= dimension, \n",
    "        distance= models.Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "# creacion de los Puntos\n",
    "# para almacenar los puntos\n",
    "points= []\n",
    "id=0 #por defecto el identificador de los puntos 0 \n",
    "\n",
    "\n",
    "for doc in documents:\n",
    "    point = models.PointStruct(\n",
    "        id=id, \n",
    "        vector = models.Document(text= doc['question'] + ' ' + doc['text'], model= modelo),\n",
    "        payload= {\"text\": doc['text'], \"section\": doc['section'], \"course\":doc[\"course\"], \"id\": doc['id']}\n",
    "    )\n",
    "    points.append(point)\n",
    "    id +=1\n",
    "\n",
    "# Insercción de los puntos en la Colección\n",
    "cliente.upsert(\n",
    "    collection_name= nombre_coleccion, \n",
    "    points= points\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35102e18",
   "metadata": {},
   "source": [
    "Función búsqueda usando Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "877efba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_qdrant(query, limit= 5):\n",
    "    results = cliente.query_points(\n",
    "        collection_name= nombre_coleccion,\n",
    "        query = models.Document( #realiza el embedding de la query localmente con el modelo elegido\n",
    "            text= query, \n",
    "            model = modelo\n",
    "        ),\n",
    "        limit = limit, # cantidad de respuestas\n",
    "        with_payload=True  # para obtener la metada en los resultados \n",
    "    )\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd9cce9",
   "metadata": {},
   "source": [
    "Necesitamos una estructura <p>\n",
    "Estrutura de los resultados esperados:\n",
    "```\n",
    "[{'text': ' ',\n",
    "  'section': '',\n",
    "  'question': '',\n",
    "  'course': 'data-engineering-zoomcamp',\n",
    "  'id': ''} \n",
    "  {...},\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9a4d0e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Environment - Should I use my local machine, GCP, or GitHub Codespaces for my environment?'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_20 = documents[20]['question']\n",
    "question_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "60bb07dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryResponse(points=[ScoredPoint(id=20, version=0, score=0.9360642, payload={'text': 'You can set it up on your laptop or PC if you prefer to work locally from your laptop or PC.\\nYou might face some challenges, especially for Windows users. If you face cnd2\\nIf you prefer to work on the local machine, you may start with the week 1 Introduction to Docker and follow through.\\nHowever, if you prefer to set up a virtual machine, you may start with these first:\\nUsing GitHub Codespaces\\nSetting up the environment on a cloudV Mcodespace\\nI decided to work on a virtual machine because I have different laptops & PCs for my home & office, so I can work on this boot camp virtually anywhere.', 'section': 'General course-related questions', 'course': 'data-engineering-zoomcamp', 'id': 'ddf6c1b3'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=23, version=0, score=0.9106379, payload={'text': 'Choose the approach that aligns the most with your idea for the end project\\nOne of those should suffice. However, BigQuery, which is part of GCP, will be used, so learning that is probably a better option. Or you can set up a local environment for most of this course.', 'section': 'General course-related questions', 'course': 'data-engineering-zoomcamp', 'id': '3c0114ce'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=22, version=0, score=0.90951645, payload={'text': \"It's up to you which platform and environment you use for the course.\\nGithub codespaces or GCP VM are just possible options, but you can do the entire course from your laptop.\", 'section': 'General course-related questions', 'course': 'data-engineering-zoomcamp', 'id': '251218fc'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=21, version=0, score=0.87302685, payload={'text': 'GitHub Codespaces offers you computing Linux resources with many pre-installed tools (Docker, Docker Compose, Python).\\nYou can also open any GitHub repository in a GitHub Codespace.', 'section': 'General course-related questions', 'course': 'data-engineering-zoomcamp', 'id': 'ac25d3af'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=135, version=0, score=0.8457154, payload={'text': 'The reason this video about the GCP VM exists is that many students had problems configuring their env. You can use your own env if it works for you.\\nAnd the advantage of using your own environment is that if you are working in a Github repo where you can commit, you will be able to commit the changes that you do. In the VM the repo is cloned via HTTPS so it is not possible to directly commit, even if you are the owner of the repo.', 'section': 'Module 1: Docker and Terraform', 'course': 'data-engineering-zoomcamp', 'id': '3184bd8b'}, vector=None, shard_key=None, order_value=None)])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados= search_qdrant(question_20)\n",
    "resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
